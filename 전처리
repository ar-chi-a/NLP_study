1. 자연어처리란?
2. 통계기반 자연어 처리 절차
3. [실습] 데이터수집 - 네이버 뉴스, 블로그 수집
 -구글 코랩에서 코드 연습
 
4. 전처리
 자연어 처리를 위해 용도에 맞도록 사전에 표준화 하는 작엄
 텍스트 내 정보를 유지하고, 분석의 효율성을 높이기 위해
 토큰화 - 형태소 분석 - 품사 태깅 - 원형 ㅂ고원 - 불용어 처리
 최근에는 모델 자체의 성능이 떨어지는 경우가 적어서 데이터 전처리 중요성이 더 높음(데이터의 품질 높여야)
 
 1) 토큰화 : 텍스트를 자연어 처리를 위해 분리하는 것. 문장토큰화, 단어토큰화로 구분
 문장토큰화 : 온점, 느낌표, 물음표 등 
 단어토큰화 : 영문의 경우 공백으로, 한글의 경우 품사를 고려한 토큰화(=형태소분석)이 필요
 
 단어 토큰화 고려사항 : 특수문자가 있는 경우(예. don't, state-of-the-art), 단어 내 띄어쓰기가 있는 경우(예. NEW YORK)
 
 2) 품사태깅(PoS tagging) : 각 토큰에 품사 정보를 추가, 분석시에 불필요한 품사를 제거하거나 필요한 품사를 필터링 하기 위해 사용
 
 3) 개체명 인식(NER, named entity recognition) : 사람, 조직, 지역, 날짜, 숫자 등 개체 유형을 식별, 검색 엔진 색인에 활용
 
 4) 원형 복원(Stemming & Lemmatization) : 
   각 토큰의 원형 복원을 함으로써 토큰을 표준화하여 불필요한 데이터 중복을 방지
   (=단어의 수를 줄일 수 있어 연산의 효율성을 높임)
  4-1) 어간추출(stemming) : 품사를 무시하고 규칙에 기반하여 어간을 추출 (예. beautiful -> beauti )
                           -> 스테밍한 결과가 완벽하게 가독가능한 것이 아님, 규칙에 기반한 것이므로 새로운 단어가 등장해도 스테밍이 가능 
                          
  4-2) 표제어추출(Lemmatization) : 품사정보를 유지하여 표제어 추출(사전기반) (예. beautiful -> beautiful )
                            -> 품질은 좋지만 사전에 없는 단어는 추출할 수 없음
  
 5) 불용어 처리(stopwords) : 불필요한 토큰, 품사를 제거하는 작업
  
 [실습] 텍스트 전처리 
   -> 구글 코랩에 실습 자료 
       
       
       
       
       
       
