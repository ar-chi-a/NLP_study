표현(Representation)
 단어를 숫자화 하는 과정
 
1. 원핫-인코딩(one-hot-encoding)
 한계점 : 차원 크기의 문제, 의미를 담지 못하는 문제, 자연어 처리 유사성 판단-코사인 유사도, 
         원핫 벡터간 코사인 유사도는 모두 0 -> 따라서 의미를 분간하기 어려움
         벡터로 표현한 단어 차원이 너무 큼 -> 연산이 낭비되어 모델 학습에 불리하게 적용
         단어 의미를 담지 못함 -> 분석을 효과적으로 수행할 수 없음
         
2. 유사도 계산(similarlity)
 유클리디언 거리, 한계점 : 
 자카드 유사도(Jaccard index) : 문서 혹은 문장간 유사도 측정 (겹치는 토큰의 비율)
 코사인 유사도(cosine similarity) : 두 벡터간 각(코사인 유사도)를 이용한 유사도 측정
 
3. 단어 임베딩(word embedding)
 원핫인코딩 단점 해결
 단어 임베딩은 단어의 의미를 간직하는 밀집 벡터(dense vector)로 표현하는 방법
 벡터가 공간에 꽉차 있음
 새로운 단어 추가시 차원을 추가할 필요가 없음 -> 차원을 줄일 수 있음 -> 연산을 줄일 수 있음
 차원이 커지는 것을 밀집 벡터로 해결
 단어들이 벡터 위에서 어디에 위치하는 것이 맞을까? -> 단어를 벡터로 표현하는 명확한 방법이 존재하지 않음
 
 밀집 벡터를 만드는 방법:
  분포가설 -> 같은 문맥에서 등장하는 단어는 유사한 의미를 지닌다 -> 같은 문맥에 등장하는 단어를 더 가까이 표현
  
 local representiation : 단어 그 자체만 보고 값을 매핑하여 표현
 distributed " : 단어를 표현하기 위해 주변을 참고
 
 
 [실습] 구글 코랩에서 진행


